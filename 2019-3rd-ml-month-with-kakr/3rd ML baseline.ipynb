{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Prepare the Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"### Load library\n\n기본적인 라이브러리를 로드한다.\n이번 베이스라인은 케라스 pretrained 모델 기반으로 실행된다."},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nfrom keras import backend as K\nwarnings.filterwarnings(action='ignore')\n\nK.image_data_format()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### File load\n\n주어진 파일을 확인하고 로드한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = '../input'\nos.listdir(DATA_PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> os.path.join : 경로를 병합하여 새 경로를 생성.\n\nex) os.path.join('C:\\Tmp', 'a', 'b') : \"C:\\Tmp\\a\\b\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이미지 폴더 경로\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\nTEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n\n# CSV 파일 경로\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration\n\n실제 데이터가 Description과 일치하는지, 데이터는 어떻게 구성되어 있고 클래스 별로 어떤 분포를 가지고 있는지 등 데이터에 대한 전반적인 궁금증을 해결해보는 과정."},{"metadata":{},"cell_type":"markdown","source":"### Check Data\n\nData Description에 나와 있는 컬럼 별 세부 설명.\n\n- img_file : 데이터셋의 각 로우와 연결되는 이미지 파일 이름.\n- bbox_x1 : 바운딩 박스 x1 좌표 (좌상단 x)\n- bbox_y1 : 바운딩 박스 y1 좌표 (좌상단 y)\n- bbox_x2 : 바운딩 박스 x2 좌표 (우하단 x)\n- bbox_y2 : 바운딩 박스 y2 좌표 (우하단 y)\n- class : 예측하려는 차종(Target)\n- id : 각 데이터셋에 기입되어 있는 클래스 id\n- name : 클래스 id에 대응되는 실제 차종 레이블"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data 누락 체크\nif set(list(df_train.img_file)) == set(os.listdir(TRAIN_IMG_PATH)):\n    print(\"Train file 누락 없음!\")\nelse:\n    print(\"Train file 누락\")\n    \nif set(list(df_test.img_file)) == set(os.listdir(TEST_IMG_PATH)):\n    print(\"Test file 누락 없음!\")\nelse:\n    print(\"Test file 누락\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data 개수\nprint(\"Number of Train Data : {}\".format(df_train.shape[0]))\nprint(\"Number of Test Data : {}\".format(df_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"타겟 클래스 총 개수 : {}\".format(df_class.shape[0]))\nprint(\"Train Data의 타겟 종류 개수 : {}\".format(df_train['class'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Class Distribution\n\n분류 문제에서 가장 먼저 의심해봐야 할 부분이 바로 Target Class의 분포입니다. 학습에 사용해야 하는 Train Set의 타겟 분포를 확인해서 밸런스가 어느 정도인지 체크해야 합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.countplot(df_train[\"class\"], order=df_train[\"class\"].value_counts(ascending=True).index)\nplt.title(\"Number of data per each class\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cntEachClass = df_train[\"class\"].value_counts(ascending=False)\nprint(\"Class with most count : {}\".format(cntEachClass.index[0]))\nprint(\"Most Count : {}\".format(cntEachClass.max()))\n\nprint(\"Class with fewest count : {}\".format(cntEachClass.index[-1]))\nprint(\"Fewest Count : {}\".format(cntEachClass.min()))\n\nprint(\"Mean : {}\".format(cntEachClass.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cntEachClass.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cntEachClass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Image Visualization\n\n파이썬 커널에서 이미지를 로드하는 방법은 여러가지가 있지만, 이 커널에서는 PIL 라이브러리를 사용합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL\nfrom PIL import ImageDraw\n\ntmp_imgs = df_train['img_file'][100:110]\nplt.figure(figsize=(12, 20))\n\nfor num, f_name in enumerate(tmp_imgs):\n    img = PIL.Image.open(os.path.join(TRAIN_IMG_PATH, f_name))\n    plt.subplot(5, 2, num+1)\n    plt.title(f_name)\n    plt.imshow(img)\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bounding Box\n\n> 바운딩 박스란?\n\n이미지 내부에서 특정 Object를 박스로 레이블한 좌표를 말하며, 보통 좌측 상단 (x1, y1)과 우측 하단(x2, y2) 좌표가 주어져서 직사각형 모양의 박스를 그릴 수 있게 됩니다. 이 때, 좌표는 이미지의 픽셀 좌표입니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_rect(drawcontext, pos, outline=None, width=0):\n    (x1, y1) = (pos[0], pos[1])\n    (x2, y2) = (pos[2], pos[3])\n    points = (x1, y1), (x2, y1), (x2, y2), (x1, y2), (x1, y1)\n    drawcontext.line(points, fill=outline, width=width)\n    \ndef make_boxing_img(img_name):\n    if img_name.split('_')[0] == \"train\":\n        PATH = TRAIN_IMG_PATH\n        data = df_train\n    elif img_name.split('_')[0] == \"test\":\n        PATH = TEST_IMG_PATH\n        data = df_test\n        \n    img = PIL.Image.open(os.path.join(PATH, img_name))\n    pos = data.loc[data[\"img_file\"] == img_name, ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n    draw = ImageDraw.Draw(img)\n    draw_rect(draw, pos, outline='red', width=10)\n    \n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_name = \"train_00102.jpg\"\n\nplt.figure(figsize=(20, 10))\nplt.subplot(1, 2, 1)\n\n# Original Image\norigin_img = PIL.Image.open(os.path.join(TRAIN_IMG_PATH, f_name))\nplt.title(\"Original Image - {}\".format(f_name))\nplt.imshow(origin_img)\nplt.axis('off')\n\n# Image included bounding box\nplt.subplot(1, 2, 2)\nboxing = make_boxing_img(f_name)\nplt.title(\"Boxing Image - {}\".format(f_name))\nplt.imshow(boxing)\nplt.axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"왼쪽 그림과 같이 어떤 이미지에는 내가 필요로 하는 Target Object 뿐만 아니라 상관 없는 다른 Object(Noise)가 섞여 있을 수 있습니다. 이런 경우에 이미지 내부에서 필요한 Object를 명확히 표시하기 위해 Bounding Box를 사용합니다. (실제로 이미지를 모델에 넣을 때는 Box 바깥 부분은 잘라서 사용합니다.)\n\n이번 컴페티션은 Bounding Box 좌표가 이미 주어져 있습니다. 만약 Bounding Box 좌표가 주어지지 않는다면 직접 레이블을 하거나, 좌표를 예측하는 딥러닝 모델을 설계해볼 수도 있습니다."},{"metadata":{},"cell_type":"markdown","source":"## Model\n\n이번 커널에서는 ResNet50 Pretrained Model을 불러와서 사용합니다."},{"metadata":{},"cell_type":"markdown","source":"### Train set, Valid set Split\n\n모델 학습을 하기 전에 주어진 Train 데이터셋을 어떻게 활용할 지 생각해야합니다."},{"metadata":{},"cell_type":"markdown","source":"#### Train_test_split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_train[\"class\"] = df_train[\"class\"].astype('str')\n\ndf_train = df_train[['img_file', 'class']]\ndf_test = df_test[['img_file']]\n\nits = np.arange(df_train.shape[0])\ntrain_idx, val_idx = train_test_split(its, train_size = 0.8, random_state = 42)\n\nX_train = df_train.iloc[train_idx, :]\nX_val = df_train.iloc[val_idx, :]\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generator\n\n> Generator의 이점?\n\n제너레이터는 코랩이나 캐글 커널같은 클라우드 환경 또는 일반적인 로컬 환경에서 정말 유용하게 쓰일 수 있습니다. 그 이유는 보통 이러한 환경은 메모리가 충분하지 않기 때문입니다. 특히나 이미지처럼 파일 하나의 용량이 매우 큰 경우, 한 번에 모든 파일을 메모리에 적재하게 되면 상당히 큰 부담이 됩니다. 배치사이즈 단위만큼 파일을 불러와 학습하고 끝나면 다시 불러와서 학습하는 방법을 반복하기 때문에 전체 학습을 하더라도 메모리를 조금만 사용하게 되는 것입니다.\n\n> Keras DataGenerator\n\n지금껏 불편하게 제너레이터를 만들어 사용했다면 케라스에는 정말 편한 제너레이터 함수가 있씁니다.\n케라스 ImageDataGenerator는 제너레이터의 기능은 물론 제너레이터를 정의하면서 동시에 Data에 원하는 Noise까지 부여할 수 있습니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Parameter\nimg_size = (224, 224)\nnb_train_samples = len(X_train)\nnb_validation_samples = len(X_val)\nnb_test_samples = len(df_test)\nepochs = 20\nbatch_size = 32\n\n# Define Generator config\ntrain_datagen = ImageDataGenerator(\n    horizontal_flip = True,\n    vertical_flip = False,\n    zoom_range = 0.10,\n    preprocessing_function = preprocess_input)\n\nval_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\ntest_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n\n# Make Generator\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe = X_train,\n    directory = '../input/train',\n    x_col = 'img_file',\n    y_col = 'class',\n    target_size = img_size,\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    batch_size = batch_size,\n    seed = 42\n)\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n    dataframe=X_val, \n    directory='../input/train',\n    x_col = 'img_file',\n    y_col = 'class',\n    target_size = img_size,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=batch_size,\n    shuffle=False\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe = df_test,\n    directory = '../input/test',\n    x_col = 'img_file',\n    y_col = None,\n    target_size = img_size,\n    color_mode = 'rgb',\n    class_mode = None,\n    batch_size = batch_size,\n    shuffle = False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Pretrained Model - ResNet50\n\n보통 딥러닝 모델을 구성할 때 직접 만들어 보는것도 좋지만, 이 작업은 상당히 많은 시간과 노력이 필요하기 때문에 이미 성능이 입증된 모델을 불러와서 사용해보는 것도 좋은 방법입니다.\n\nPretrained Model을 불러오기 위해서는 커널의 Internet 옵션이 활성화 되어 있어야 합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"resNet_model = ResNet50(include_top = False, input_shape = (224, 224, 3))\n# resNet_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, GlobalAveragePooling2D\n\nmodel = Sequential()\nmodel.add(resNet_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(196, activation='softmax', kernel_initializer='he_normal'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pretrained Model을 사용할 때 한 가지 주의할 점이 있습니다.\n\nPretrained 모델은 경우에 따라 다양하게 사용될 수 있기 때문에 Model output 부분을 잘라버린 채 로드되는 경우가 있습니다. (include_top = False)\n\n이 경우에는 직접 output을 만들어야하므로 우리는 196개의 class를 분류하기 때문에 위와 같이 만들었습니다.\n\n참고)\nKeras에는 모델을 생성하는 방법이 2가지가 있습니다.\n\n하나는 위 처럼 Sequential을 사용하는 것이고 다른 하나는 Model을 사용하는 방법입니다.\n\n2가지 모두 많이 사용하니 Model도 한 번 사용해보시길 권유드립니다."},{"metadata":{},"cell_type":"markdown","source":"### Model Compile\n\n이제 Model을 만들었으니 어떻게 학습할 지 정해야합니다. 어떤 방법으로, 어떤 속도로, 어떤 지표를 기준으로 등등 정할 수 있고 필요시에는 각각의 함수를 직접 구현해볼 수도 있습니다. 하지만 보통은 기본으로 주어지는 것들을 사용합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef micro_f1(y_true, y_pred):\n    return f1_score(y_true, y_pred, average='micro')\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Training\n\n이제 진짜로 학습을 시작해봅시다!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_steps(num_samples, batch_size):\n    if (num_samples % batch_size) > 0:\n        return (num_samples // batch_size) + 1\n    else:\n        return num_samples // batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfilepath = \"my_resnet_model_{val_acc:.2f}_{val_loss:.4f}.h5\"\nes = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')\n\ncallbackList = [es]\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = get_steps(nb_train_samples, batch_size),\n    epochs = epochs,\n    validation_data = validation_generator,\n    validation_steps = get_steps(nb_validation_samples, batch_size),\n    callbacks = callbackList\n)\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training History Visualization\n\n학습된 결과를 plot으로 그려볼 수 있습니다. 모델 학습 로그를 통해서 확인할 수도 있지만, 전반적인 학습 형태를 한 눈에 파악하기에는 그래프만 한 것이 없습니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict & Make submission\n\n모델이 테스트 데이터에도 잘 적용되는지 predict를 해보고 제출물을 만들어봅시다."},{"metadata":{},"cell_type":"markdown","source":"### Model Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_generator.reset()\nprediction = model.predict_generator(\n    generator = test_generator,\n    steps = get_steps(nb_test_samples, batch_size),\n    verbose = 1\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict 또한 제너레이터를 사용합니다. 제너레이터는 메모리가 부족한 우리들에게 꼭 필요한 기능입니다!"},{"metadata":{},"cell_type":"markdown","source":"### Make Submission\n\nInference가 끝난 결과를 이제 sample_submission 파일에 매핑해야 합니다.\n\nsample_submission 파일을 불러온 후 예측한 결과를 매핑합니다.\n\n**중요**\n케라스 제너레이터를 사용하는 경우에는 타겟(클래스)의 카테고리컬 매핑이 제너레이터 임의로 결정됩니다. 따라서 제너레이터가 가지고 있는 class index 딕셔너리를 불러와 새롭게 매핑해주어야 합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_class_indices=np.argmax(prediction, axis=1)\n\n# Generator class dictionary mapping\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\n\nsubmission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\nsubmission[\"class\"] = predictions\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}
